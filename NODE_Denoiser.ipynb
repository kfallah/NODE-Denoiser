{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from models.DnCNN import DnCNN\n",
    "from models.NODE import NODEDenoiser\n",
    "from utils.dataloaders import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters, Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU device\n",
    "device = 'cuda:3'\n",
    "\n",
    "# standard dev for noise\n",
    "noise_level = 25\n",
    "NODE_network = False\n",
    "\n",
    "num_epochs = 180\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "scales = [1, 0.9, 0.8, 0.7]\n",
    "patch_per_image = 150\n",
    "patch_size = 40\n",
    "train_file_path = './data/train/'\n",
    "test_file_path = './data/Set68/'\n",
    "\n",
    "# Create patches realtime (may throttle CPU/not utilize GPU)\n",
    "realtime_patch = True\n",
    "\n",
    "# Use CUDA when available\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is dedicated to constructing a method of generating a database for patches to prevent CPU throttling during data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Image Iter 67 of 68 400\r"
     ]
    }
   ],
   "source": [
    "if realtime_patch:\n",
    "    files = glob.glob(os.path.join(train_file_path, '*.png'))\n",
    "    files.sort()\n",
    "    train_patches = []\n",
    "    for i in range(len(files)):\n",
    "        image = Image.open(files[i])\n",
    "        height, width = image.size\n",
    "        for scale in scales:\n",
    "            im_re = image.resize((int(height*scale), int(width*scale)), Image.BICUBIC)\n",
    "            im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "            patches = np.expand_dims(extract_patches_2d(im, (patch_size,patch_size), max_patches=patch_per_image), axis=1)\n",
    "            train_patches.append(patches)\n",
    "\n",
    "        print('Train Image Iter {} of {}'.format(i, len(files)), end='\\r')    \n",
    "    train_patches = np.array(train_patches)\n",
    "    train_patches = train_patches.reshape((-1,) + train_patches.shape[-3:])\n",
    "    \n",
    "    files = glob.glob(os.path.join(test_file_path, '*.png'))\n",
    "    files.sort()\n",
    "    test_images = []\n",
    "    for i in range(len(files)):\n",
    "        image = Image.open(files[i])\n",
    "        im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "        if NODE_network:\n",
    "            image = np.expand_dims(extract_patches_2d(im, (patch_size,patch_size), max_patches=patch_per_image), axis=1)\n",
    "        else:\n",
    "            image = np.expand_dims(im, axis=0)\n",
    "        test_images.append(image)\n",
    "\n",
    "        print('Val Image Iter {} of {}'.format(i, len(files)), end='\\r')\n",
    "    test_images = np.array(test_images)\n",
    "else:\n",
    "    if not os.path.exists(\"/scratch/NODE-Denoiser/denoising_train.hdf5\"):\n",
    "        f = h5py.File(\"/scratch/NODE-Denoiser/denoising_train.hdf5\", \"w\")\n",
    "\n",
    "        files = glob.glob(os.path.join(train_file_path, '*.png'))\n",
    "        files.sort()\n",
    "        train_num = 0\n",
    "        for i in range(len(files)):\n",
    "            image = Image.open(files[i])\n",
    "            height, width = image.size\n",
    "            for scale in scales:\n",
    "                im_re = image.resize((int(height*scale), int(width*scale)), Image.BICUBIC)\n",
    "                im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "                patches = np.expand_dims(extract_patches_2d(im, (patch_size,patch_size), max_patches=patch_per_image), axis=1)\n",
    "                for j in range(patches.shape[0]):\n",
    "                    f.create_dataset(str(train_num), data=patches[j,:], dtype='f4')\n",
    "                    train_num += 1\n",
    "\n",
    "            print('Train Image Iter {} of {}'.format(i, len(files)), end='\\r')\n",
    "\n",
    "    if not os.path.exists(\"/scratch/NODE-Denoiser/denoising_test.hdf5\"):\n",
    "        f = h5py.File(\"/scratch/NODE-Denoiser/denoising_test.hdf5\", \"w\")\n",
    "\n",
    "        files = glob.glob(os.path.join(test_file_path, '*.png'))\n",
    "        files.sort()\n",
    "        train_num = 0\n",
    "        for i in range(len(files)):\n",
    "            image = Image.open(files[i])\n",
    "            im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "            patches = np.expand_dims(im, axis=0)\n",
    "            f.create_dataset(str(train_num), data=patches, dtype='f4')\n",
    "            train_num += 1\n",
    "\n",
    "            print('Val Image Iter {} of {}'.format(i, len(files)), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if realtime_patch:\n",
    "    #trainloader = data.DataLoader(RandomPatchDataset(train_file_path, patch_size=patch_size, transform=patch_transform), \n",
    "    #                              batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    #testloader = data.DataLoader(RandomPatchDataset(test_file_path, train_data=False), \n",
    "    #                             batch_size=1, shuffle=False, num_workers=4)\n",
    "    trainloader = data.DataLoader(ImageDataset(train_patches, augment=True), \n",
    "                                  batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    testloader = data.DataLoader(ImageDataset(test_images, augment=False),\n",
    "                                batch_size=1, shuffle=False, num_workers=4)\n",
    "else:\n",
    "    trainloader = data.DataLoader(h5pyDataset('/scratch/NODE-Denoiser/denoising_train.hdf5', augment=True), \n",
    "                                  batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    testloader = data.DataLoader(h5pyDataset('/scratch/NODE-Denoiser/denoising_test.hdf5'), \n",
    "                                 batch_size=1, shuffle=False, num_workers=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NODE_network:\n",
    "    model = NODEDenoiser()\n",
    "else:\n",
    "    model = DnCNN()\n",
    "    \n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)\n",
    "criterion = nn.MSELoss(reduction='sum').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    scheduler.step(epoch)\n",
    "    model.train()\n",
    "    for batch_count, batch_data in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        img_clean = batch_data\n",
    "        noise = torch.FloatTensor(img_clean.size()).normal_(mean=0, std=noise_level/255.)\n",
    "        img_clean, noise = img_clean.to(device), noise.to(device)\n",
    "                \n",
    "        loss = 0.5*criterion(model(img_clean + noise), img_clean)\n",
    "        print('Train iter: {} of {}, loss: {}'.format(batch_count+1, trainloader.__len__(), loss.item()), end='\\r')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_psnr = []\n",
    "    val_ssim = []\n",
    "    with torch.no_grad():\n",
    "        for batch_count, batch_data in enumerate(testloader):\n",
    "            img_clean = batch_data\n",
    "            noise = torch.FloatTensor(img_clean.size()).normal_(mean=0, std=noise_level/255.)\n",
    "            img_clean, noise = img_clean.to(device), noise.to(device)\n",
    "        \n",
    "            img_est = torch.clamp(model(img_clean + noise), 0., 1.).detach().cpu().numpy()\n",
    "            img_clean = torch.clamp(img_clean, 0., 1.).detach().cpu().numpy()\n",
    "            \n",
    "            val_psnr.append(compare_psnr(img_est, img_clean))\n",
    "            val_ssim.append(compare_ssim(np.squeeze(img_est), np.squeeze(img_clean)))\n",
    "    \n",
    "    print('Epoch {} of {}, Val PSNR: {:4f}, Val SSIM: {:4f}'.format(epoch+1, num_epochs, np.mean(val_psnr), np.mean(val_ssim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mstar)",
   "language": "python",
   "name": "mstar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
