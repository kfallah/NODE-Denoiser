{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from skimage.measure.simple_metrics import compare_psnr\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from models.DnCNN import DnCNN\n",
    "from models.NODE import NODEDenoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters, Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU device\n",
    "device = 'cuda:0'\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# standard dev for noise\n",
    "noise_level = 25\n",
    "NODE_network = True\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "\n",
    "scales = [1, 0.9, 0.8, 0.7]\n",
    "patch_per_image = 1000\n",
    "patch_size = 10\n",
    "train_file_path = './data/train/'\n",
    "test_file_path = './data/Set68/'\n",
    "\n",
    "# Create patches realtime (may throttle CPU/not utilize GPU)\n",
    "realtime_patch = True\n",
    "\n",
    "# Use CUDA when available\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is dedicated to constructing a method of generating a database for patches to prevent CPU throttling during data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Image Iter 67 of 68 400\r"
     ]
    }
   ],
   "source": [
    "if realtime_patch:\n",
    "    files = glob.glob(os.path.join(train_file_path, '*.png'))\n",
    "    files.sort()\n",
    "    train_patches = []\n",
    "    for i in range(len(files)):\n",
    "        image = Image.open(files[i])\n",
    "        height, width = image.size\n",
    "        for scale in scales:\n",
    "            im_re = image.resize((int(height*scale), int(width*scale)), Image.BICUBIC)\n",
    "            im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "            patches = np.expand_dims(extract_patches_2d(im, (patch_size,patch_size), max_patches=1), axis=1)\n",
    "            train_patches.append(patches)\n",
    "\n",
    "        print('Train Image Iter {} of {}'.format(i, len(files)), end='\\r')    \n",
    "    train_patches = np.array(train_patches)\n",
    "    train_patches = train_patches.reshape((-1,) + train_patches.shape[-3:])\n",
    "    \n",
    "    files = glob.glob(os.path.join(test_file_path, '*.png'))\n",
    "    files.sort()\n",
    "    test_images = []\n",
    "    for i in range(len(files)):\n",
    "        image = Image.open(files[i])\n",
    "        im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "        image = np.expand_dims(im, axis=0)\n",
    "        test_images.append(image)\n",
    "\n",
    "        print('Val Image Iter {} of {}'.format(i, len(files)), end='\\r')\n",
    "    test_images = np.array(test_images)\n",
    "else:\n",
    "    if not os.path.exists(\"/scratch/NODE-Denoiser/denoising_train.hdf5\"):\n",
    "        f = h5py.File(\"/scratch/NODE-Denoiser/denoising_train.hdf5\", \"w\")\n",
    "\n",
    "        files = glob.glob(os.path.join(train_file_path, '*.png'))\n",
    "        files.sort()\n",
    "        train_num = 0\n",
    "        for i in range(len(files)):\n",
    "            image = Image.open(files[i])\n",
    "            height, width = image.size\n",
    "            for scale in scales:\n",
    "                im_re = image.resize((int(height*scale), int(width*scale)), Image.BICUBIC)\n",
    "                im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "                patches = np.expand_dims(extract_patches_2d(im, (patch_size,patch_size), max_patches=patch_per_image), axis=1)\n",
    "                for j in range(patches.shape[0]):\n",
    "                    f.create_dataset(str(train_num), data=patches[j,:], dtype='f4')\n",
    "                    train_num += 1\n",
    "\n",
    "            print('Train Image Iter {} of {}'.format(i, len(files)), end='\\r')\n",
    "\n",
    "    if not os.path.exists(\"/scratch/NODE-Denoiser/denoising_test.hdf5\"):\n",
    "        f = h5py.File(\"/scratch/NODE-Denoiser/denoising_test.hdf5\", \"w\")\n",
    "\n",
    "        files = glob.glob(os.path.join(test_file_path, '*.png'))\n",
    "        files.sort()\n",
    "        train_num = 0\n",
    "        for i in range(len(files)):\n",
    "            image = Image.open(files[i])\n",
    "            im = np.float32(np.array(im_re) / 255., axis=0)\n",
    "            patches = np.expand_dims(im, axis=0)\n",
    "            f.create_dataset(str(train_num), data=patches, dtype='f4')\n",
    "            train_num += 1\n",
    "\n",
    "            print('Val Image Iter {} of {}'.format(i, len(files)), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPatchDataset(data.Dataset):\n",
    "    'Characterizes a dataset for loading patches for denoising'\n",
    "    \n",
    "    def __init__(self, filepath, patch_size=0, train_data=True, transform=None):\n",
    "        'Initialization'\n",
    "        super(RandomPatchDataset, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.transform = transform\n",
    "        self.files = glob.glob(os.path.join(filepath, '*.png'))\n",
    "        self.train_data = train_data\n",
    "                        \n",
    "        if self.train_data:\n",
    "            self.length = len(self.files) * len(scales) * patch_per_image\n",
    "        else:\n",
    "            self.length = len(self.files)\n",
    "            \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one single image patch'\n",
    "        file_idx = (index // (len(scales) * patch_per_image)) % len(self.files)\n",
    "        scale_idx = (index // patch_per_image) % len(scales)\n",
    "        patch_idx = index % patch_per_image\n",
    "        \n",
    "        if not self.train_data:\n",
    "            image = Image.open(self.files[index])\n",
    "        else:\n",
    "            image = Image.open(self.files[file_idx])\n",
    "            if self.transform is not None:        \n",
    "                image = self.transform(image)\n",
    "        if self.train_data:\n",
    "            height, width = image.size\n",
    "            image = image.resize((int(height*scales[scale_idx]), int(width*scales[scale_idx])), Image.BICUBIC)\n",
    "        patch = image = np.float32(np.array(image) / 255., axis=0)\n",
    "        if self.train_data:\n",
    "            patch = np.expand_dims(extract_patches_2d(image, (self.patch_size, self.patch_size), \n",
    "                                                  max_patches=patch_per_image), axis=1)[patch_idx,:]  \n",
    "        return torch.Tensor(patch)\n",
    "    \n",
    "class h5pyDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, file_name, augment=False):\n",
    "        'Initialization'\n",
    "        super(h5pyDataset, self).__init__()\n",
    "        self.file_name = file_name\n",
    "        self.augment = augment\n",
    "        with h5py.File(self.file_name, 'r') as db:\n",
    "            self.length = len(db.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        with h5py.File(self.file_name, 'r') as db:\n",
    "            image = np.array(db[str(index)])\n",
    "    \n",
    "        if self.augment:\n",
    "            data_augmentation(image)\n",
    "            \n",
    "        return torch.Tensor(image)\n",
    "    \n",
    "class ImageDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, images, augment=False):\n",
    "        'Initialization'\n",
    "        super(ImageDataset, self).__init__()\n",
    "        self.images = images\n",
    "        self.images = torch.Tensor(self.images)\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        image = self.images[index, :]\n",
    "    \n",
    "        if self.augment:\n",
    "            data_augmentation(image)\n",
    "            \n",
    "        return image\n",
    "    \n",
    "def data_augmentation(image):\n",
    "    out = np.transpose(image, (1,2,0))\n",
    "    mode = np.random.randint(0,8)\n",
    "    if mode == 0:\n",
    "        # original\n",
    "        out = out\n",
    "    elif mode == 1:\n",
    "        # flip up and down\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 2:\n",
    "        # rotate counterwise 90 degree\n",
    "        out = np.rot90(out)\n",
    "    elif mode == 3:\n",
    "        # rotate 90 degree and flip up and down\n",
    "        out = np.rot90(out)\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 4:\n",
    "        # rotate 180 degree\n",
    "        out = np.rot90(out, k=2)\n",
    "    elif mode == 5:\n",
    "        # rotate 180 degree and flip\n",
    "        out = np.rot90(out, k=2)\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 6:\n",
    "        # rotate 270 degree\n",
    "        out = np.rot90(out, k=3)\n",
    "    elif mode == 7:\n",
    "        # rotate 270 degree and flip\n",
    "        out = np.rot90(out, k=3)\n",
    "        out = np.flipud(out)\n",
    "    return np.transpose(out, (2,0,1))\n",
    "        \n",
    "if realtime_patch:\n",
    "    #trainloader = data.DataLoader(RandomPatchDataset(train_file_path, patch_size=patch_size, transform=patch_transform), \n",
    "    #                              batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    #testloader = data.DataLoader(RandomPatchDataset(test_file_path, train_data=False), \n",
    "    #                             batch_size=1, shuffle=False, num_workers=4)\n",
    "    trainloader = data.DataLoader(ImageDataset(train_patches, augment=True), \n",
    "                                  batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    testloader = data.DataLoader(ImageDataset(test_images, augment=False),\n",
    "                                batch_size=1, shuffle=False, num_workers=4)\n",
    "else:\n",
    "    trainloader = data.DataLoader(h5pyDataset('/scratch/NODE-Denoiser/denoising_train.hdf5', augment=True), \n",
    "                                  batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    testloader = data.DataLoader(h5pyDataset('/scratch/NODE-Denoiser/denoising_test.hdf5'), \n",
    "                                 batch_size=1, shuffle=False, num_workers=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NODE_network:\n",
    "    model = NODEDenoiser()\n",
    "else:\n",
    "    model = DnCNN(1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter: 100 of 100, loss: 0.0053953551687300205\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_count, batch_data in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        image_clean = batch_data\n",
    "        noise = torch.FloatTensor(image_clean.size()).normal_(mean=0, std=noise_level/255.)\n",
    "        image_clean, noise = image_clean.to(device), noise.to(device)\n",
    "        \n",
    "        noise_est = model(image_clean + noise)\n",
    "        \n",
    "        loss = criterion(noise_est, noise)\n",
    "        print('Train iter: {} of {}, loss: {}'.format(batch_count+1, trainloader.__len__(), loss.item()), end='\\r')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_psnr = []\n",
    "    with torch.no_grad():\n",
    "        for batch_count, batch_data in enumerate(testloader):\n",
    "            image_clean = batch_data\n",
    "            noise = torch.FloatTensor(image_clean.size()).normal_(mean=0, std=noise_level/255.)\n",
    "            image_clean, noise = image_clean.to(device), noise.to(device)\n",
    "        \n",
    "            noise_est = model(image_clean + noise)\n",
    "            img_est = torch.clamp(image_clean+noise-noise_est, 0., 1.)\n",
    "            \n",
    "            val_psnr.append(compare_psnr(img_est.detach().cpu().numpy(), image_clean.detach().cpu().numpy(), 1.))\n",
    "    \n",
    "    print('Epoch {} of {}, Val PSNR: {:4f}'.format(epoch+1, num_epochs, val_psnr[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mstar)",
   "language": "python",
   "name": "mstar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
